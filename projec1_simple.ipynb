{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = 'data/train.csv' \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.99000e+02,  1.62172e+02,  1.25953e+02,  3.56350e+01,\n",
       "       -9.99000e+02, -9.99000e+02, -9.99000e+02,  3.14800e+00,\n",
       "        9.33600e+00,  1.97814e+02,  3.77600e+00,  1.41400e+00,\n",
       "       -9.99000e+02,  3.21540e+01, -7.05000e-01, -2.09300e+00,\n",
       "        1.21409e+02, -9.53000e-01,  1.05200e+00,  5.42830e+01,\n",
       "       -2.18600e+00,  2.60414e+02,  1.00000e+00,  4.42510e+01,\n",
       "        2.05300e+00, -2.02800e+00, -9.99000e+02, -9.99000e+02,\n",
       "       -9.99000e+02,  4.42510e+01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missing_values import *\n",
    "\n",
    "interpolator = MeanInterpolator()\n",
    "X = interpolator.interpolate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.21858528e+02,  1.62172000e+02,  1.25953000e+02,  3.56350000e+01,\n",
       "        2.40373503e+00,  3.71783360e+02, -8.21688171e-01,  3.14800000e+00,\n",
       "        9.33600000e+00,  1.97814000e+02,  3.77600000e+00,  1.41400000e+00,\n",
       "        4.58289801e-01,  3.21540000e+01, -7.05000000e-01, -2.09300000e+00,\n",
       "        1.21409000e+02, -9.53000000e-01,  1.05200000e+00,  5.42830000e+01,\n",
       "       -2.18600000e+00,  2.60414000e+02,  1.00000000e+00,  4.42510000e+01,\n",
       "        2.05300000e+00, -2.02800000e+00,  5.76794744e+01, -1.18452642e-02,\n",
       "       -1.58228913e-03,  4.42510000e+01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQoElEQVR4nO3df6zddX3H8edr/JL4Yy1SCKFkxa1/yMyG2EATloXJVgouK0sgwSyjYSRdGCaaLdnqTMamM8El04XEYbrRUBYVGWpoFFYbZDFLBLko8kPEXpFJ14ZWi4gx06Hv/XE+V4+X87n39t723Nve5yM5Od/z/n6+P94n997X/f6456aqkCRplF9a7B2QJC1dhoQkqcuQkCR1GRKSpC5DQpLUdeJi78CRdvrpp9eaNWsWezck6ZjyyCOPfKeqVk2vH3chsWbNGiYmJhZ7NyTpmJLkv0fVPd0kSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqOu7+4noh1mz97KJt+9mb37Zo25akHo8kJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqSuWUMiyTlJHkjyVJInk7yz1U9LsjvJnva8stWT5JYkk0keS3LB0Lo2t/F7kmweqr8lyeNtmVuSZKZtSJLGYy5HEi8Df1FVbwTWAzcmOQ/YCtxfVWuB+9trgMuBte2xBbgVBj/wgZuAi4ALgZuGfujf2sZOLbex1XvbkCSNwawhUVX7q+rLbfol4CngbGATsKMN2wFc2aY3AXfUwIPAiiRnAZcBu6vqUFW9AOwGNrZ5r6uqL1ZVAXdMW9eobUiSxuCwrkkkWQO8GXgIOLOq9sMgSIAz2rCzgeeGFtvbajPV946oM8M2pu/XliQTSSYOHjx4OC1JkmYw55BI8hrgk8C7qur7Mw0dUat51OesqrZV1bqqWrdq1arDWVSSNIM5hUSSkxgExEer6lOt/Hw7VUR7PtDqe4FzhhZfDeybpb56RH2mbUiSxmAudzcFuA14qqo+ODRrJzB1h9Jm4J6h+rXtLqf1wIvtVNEuYEOSle2C9QZgV5v3UpL1bVvXTlvXqG1IksZgLv/j+mLgj4HHkzzaan8N3AzcleR64NvA1W3evcAVwCTwQ+A6gKo6lOR9wMNt3Hur6lCbvgG4HTgVuK89mGEbkqQxmDUkquq/GH3dAODSEeMLuLGzru3A9hH1CeBNI+rfHbUNSdJ4+BfXkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqWvWkEiyPcmBJE8M1f42yf8kebQ9rhia9+4kk0meTnLZUH1jq00m2TpUPzfJQ0n2JPlEkpNb/ZT2erLNX3OkmpYkzc1cjiRuBzaOqH+oqs5vj3sBkpwHXAP8elvmn5OckOQE4MPA5cB5wNvbWIAPtHWtBV4Arm/164EXqurXgA+1cZKkMZo1JKrqC8ChOa5vE3BnVf2oqr4FTAIXtsdkVT1TVT8G7gQ2JQnwVuDutvwO4Mqhde1o03cDl7bxkqQxWcg1iXckeaydjlrZamcDzw2N2dtqvfrrge9V1cvT6r+wrjb/xTb+FZJsSTKRZOLgwYMLaEmSNGy+IXEr8KvA+cB+4B9bfdRv+jWP+kzremWxaltVrauqdatWrZppvyVJh2FeIVFVz1fVT6rqp8C/MDidBIMjgXOGhq4G9s1Q/w6wIsmJ0+q/sK42/5eZ+2kvSdIRMK+QSHLW0Ms/BKbufNoJXNPuTDoXWAt8CXgYWNvuZDqZwcXtnVVVwAPAVW35zcA9Q+va3KavAj7fxkuSxuTE2QYk+ThwCXB6kr3ATcAlSc5ncPrnWeBPAarqySR3AV8DXgZurKqftPW8A9gFnABsr6on2yb+Crgzyd8DXwFua/XbgH9LMsngCOKaBXcrSToss4ZEVb19RPm2EbWp8e8H3j+ifi9w74j6M/z8dNVw/X+Bq2fbP0nS0eNfXEuSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdc0aEkm2JzmQ5Imh2mlJdifZ055XtnqS3JJkMsljSS4YWmZzG78nyeah+luSPN6WuSVJZtqGJGl85nIkcTuwcVptK3B/Va0F7m+vAS4H1rbHFuBWGPzAB24CLgIuBG4a+qF/axs7tdzGWbYhSRqTWUOiqr4AHJpW3gTsaNM7gCuH6nfUwIPAiiRnAZcBu6vqUFW9AOwGNrZ5r6uqL1ZVAXdMW9eobUiSxmS+1yTOrKr9AO35jFY/G3huaNzeVpupvndEfaZtvEKSLUkmkkwcPHhwni1JkqY70heuM6JW86gflqraVlXrqmrdqlWrDndxSVLHfEPi+XaqiPZ8oNX3AucMjVsN7JulvnpEfaZtSJLGZL4hsROYukNpM3DPUP3adpfTeuDFdqpoF7Ahycp2wXoDsKvNeynJ+nZX07XT1jVqG5KkMTlxtgFJPg5cApyeZC+Du5RuBu5Kcj3wbeDqNvxe4ApgEvghcB1AVR1K8j7g4TbuvVU1dTH8BgZ3UJ0K3NcezLANSdKYzBoSVfX2zqxLR4wt4MbOerYD20fUJ4A3jah/d9Q2JEnj419cS5K6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK4FhUSSZ5M8nuTRJBOtdlqS3Un2tOeVrZ4ktySZTPJYkguG1rO5jd+TZPNQ/S1t/ZNt2SxkfyVJh+dIHEn8TlWdX1Xr2uutwP1VtRa4v70GuBxY2x5bgFthECrATcBFwIXATVPB0sZsGVpu4xHYX0nSHB2N002bgB1tegdw5VD9jhp4EFiR5CzgMmB3VR2qqheA3cDGNu91VfXFqirgjqF1SZLGYKEhUcDnkjySZEurnVlV+wHa8xmtfjbw3NCye1ttpvreEfVXSLIlyUSSiYMHDy6wJUnSlBMXuPzFVbUvyRnA7iRfn2HsqOsJNY/6K4tV24BtAOvWrRs5RpJ0+BZ0JFFV+9rzAeDTDK4pPN9OFdGeD7The4FzhhZfDeybpb56RF2SNCbzDokkr07y2qlpYAPwBLATmLpDaTNwT5veCVzb7nJaD7zYTkftAjYkWdkuWG8AdrV5LyVZ3+5qunZoXZKkMVjI6aYzgU+3u1JPBD5WVf+R5GHgriTXA98Grm7j7wWuACaBHwLXAVTVoSTvAx5u495bVYfa9A3A7cCpwH3tIUkak3mHRFU9A/zmiPp3gUtH1Au4sbOu7cD2EfUJ4E3z3UdJ0sL4F9eSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktS1kP9xrSNozdbPLsp2n735bYuyXUnHBo8kJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy39fusz5b1MlzcQjCUlS15IPiSQbkzydZDLJ1sXeH0laTpb06aYkJwAfBn4P2As8nGRnVX1tcfdMC7VYp7nAU13S4VjSIQFcCExW1TMASe4ENgGGhObN6zDS3C31kDgbeG7o9V7goumDkmwBtrSXP0jyNHA68J2jvodL13Luf0n2ng+MbVNLsv8xWc69w8L6/5VRxaUeEhlRq1cUqrYB235hwWSiqtYdrR1b6pZz/8u5d1je/S/n3uHo9L/UL1zvBc4Zer0a2LdI+yJJy85SD4mHgbVJzk1yMnANsHOR90mSlo0lfbqpql5O8g5gF3ACsL2qnpzj4ttmH3JcW879L+feYXn3v5x7h6PQf6pecYpfkiRg6Z9ukiQtIkNCktR1XIbE8fhRHkm2JzmQ5Imh2mlJdifZ055XtnqS3NL6fyzJBUPLbG7j9yTZvBi9HK4k5yR5IMlTSZ5M8s5WXy79vyrJl5J8tfX/d61+bpKHWi+faDd3kOSU9nqyzV8ztK53t/rTSS5bnI4OX5ITknwlyWfa6+XU+7NJHk/yaJKJVhvf135VHVcPBhe4vwm8ATgZ+Cpw3mLv1xHo67eBC4Anhmr/AGxt01uBD7TpK4D7GPydyXrgoVY/DXimPa9s0ysXu7c59H4WcEGbfi3wDeC8ZdR/gNe06ZOAh1pfdwHXtPpHgBva9J8BH2nT1wCfaNPnte+HU4Bz2/fJCYvd3xzfgz8HPgZ8pr1eTr0/C5w+rTa2r/3j8UjiZx/lUVU/BqY+yuOYVlVfAA5NK28CdrTpHcCVQ/U7auBBYEWSs4DLgN1VdaiqXgB2AxuP/t4vTFXtr6ovt+mXgKcY/DX+cum/quoH7eVJ7VHAW4G7W316/1Pvy93ApUnS6ndW1Y+q6lvAJIPvlyUtyWrgbcC/ttdhmfQ+g7F97R+PITHqozzOXqR9OdrOrKr9MPhBCpzR6r334Jh/b9rpgzcz+G162fTfTrc8Chxg8A3+TeB7VfVyGzLcy8/6bPNfBF7Psdv/PwF/Cfy0vX49y6d3GPxC8Lkkj2TwEUQwxq/9Jf13EvM0p4/yOM713oNj+r1J8hrgk8C7qur7g18QRw8dUTum+6+qnwDnJ1kBfBp446hh7fm46T/J7wMHquqRJJdMlUcMPe56H3JxVe1LcgawO8nXZxh7xPs/Ho8kltNHeTzfDiVpzwdavfceHLPvTZKTGATER6vqU628bPqfUlXfA/6TwfnmFUmmftEb7uVnfbb5v8zgVOWx2P/FwB8keZbBqeO3MjiyWA69A1BV+9rzAQa/IFzIGL/2j8eQWE4f5bETmLpLYTNwz1D92nanw3rgxXZIugvYkGRluxtiQ6stae2c8m3AU1X1waFZy6X/Ve0IgiSnAr/L4LrMA8BVbdj0/qfel6uAz9fg6uVO4Jp2B9C5wFrgS+PpYn6q6t1Vtbqq1jD4Xv58Vf0Ry6B3gCSvTvLaqWkGX7NPMM6v/cW+cn80Hgyu8H+DwXnb9yz2/hyhnj4O7Af+j8FvBdczONd6P7CnPZ/WxobBP2v6JvA4sG5oPX/C4KLdJHDdYvc1x95/i8Gh8WPAo+1xxTLq/zeAr7T+nwD+ptXfwOAH3STw78Aprf6q9nqyzX/D0Lre096Xp4HLF7u3w3wfLuHndzcti95bn19tjyenfp6N82vfj+WQJHUdj6ebJElHiCEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1PX/fRFRCpYZ5+oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "ditribution of the labels among the outliers :\n",
      "737 -1s and 2556 1s ratio= 0.2883411580594679\n",
      "Number of outliers removed :  3293\n"
     ]
    }
   ],
   "source": [
    "outlier_mask=np.linalg.norm(X,axis=1)<1500\n",
    "plt.hist(np.linalg.norm(X,axis=1))\n",
    "plt.show()\n",
    "print(outlier_mask.shape)\n",
    "# outliers removal\n",
    "X = X[outlier_mask]\n",
    "print('ditribution of the labels among the outliers :')\n",
    "print(np.sum(y[~outlier_mask]==-1),'-1s and',np.sum(y[~outlier_mask]==1),'1s ratio=',np.sum(y[~outlier_mask]==-1)/np.sum(y[~outlier_mask]==1) )\n",
    "y = y[outlier_mask]\n",
    "print('Number of outliers removed : ', np.sum(~outlier_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    def lambda_(x):\n",
    "        res=0\n",
    "        if x>0:\n",
    "            res=1   \n",
    "        return res\n",
    "    return [lambda_(x) for x in y]\n",
    "\n",
    "\n",
    "def inv_transform_y(y):\n",
    "    def lambda_(x):\n",
    "        res=-1\n",
    "        if x>0:\n",
    "            res=1\n",
    "        return res\n",
    "    return [lambda_(x) for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(transform_y(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration = 0, loss=104532.17322843565\n",
      "Current iteration = 500, loss=71474.53226354894\n",
      "Current iteration = 1000, loss=70105.59972067006\n",
      "Current iteration = 1500, loss=69401.75488437702\n",
      "Evaluated for {'degree': 3, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8126243643599381\n",
      "Current iteration = 0, loss=104533.90665177607\n",
      "Current iteration = 500, loss=71809.999206305\n",
      "Current iteration = 1000, loss=70645.9480382615\n",
      "Current iteration = 1500, loss=70110.38727757215\n",
      "Evaluated for {'degree': 3, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.8118505416758789\n",
      "Current iteration = 0, loss=104599.52586696087\n",
      "Current iteration = 500, loss=71309.26410093537\n",
      "Current iteration = 1000, loss=69875.7425747553\n",
      "Current iteration = 1500, loss=69137.48047612437\n",
      "Evaluated for {'degree': 4, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8124892524627214\n",
      "Current iteration = 0, loss=104601.318767807\n",
      "Current iteration = 500, loss=71648.44612894372\n",
      "Current iteration = 1000, loss=70426.04936838793\n",
      "Current iteration = 1500, loss=69861.25867169535\n",
      "Evaluated for {'degree': 4, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.8115066204829636\n",
      "Current iteration = 0, loss=104851.42519676092\n",
      "Current iteration = 500, loss=71175.34527834493\n",
      "Current iteration = 1000, loss=69758.4708033165\n",
      "Current iteration = 1500, loss=69037.96975277456\n",
      "Evaluated for {'degree': 5, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8126243643599381\n",
      "Current iteration = 0, loss=104853.26312198091\n",
      "Current iteration = 500, loss=71515.91903764756\n",
      "Current iteration = 1000, loss=70308.38349318627\n",
      "Current iteration = 1500, loss=69758.96910696954\n",
      "Evaluated for {'degree': 5, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.811346942786253\n",
      "Current iteration = 0, loss=104848.92776057788\n",
      "Current iteration = 500, loss=71089.3747539156\n",
      "Current iteration = 1000, loss=69705.77854421185\n",
      "Current iteration = 1500, loss=69015.16588785948\n",
      "Evaluated for {'degree': 6, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8125506669614563\n",
      "Current iteration = 0, loss=104850.80842276094\n",
      "Current iteration = 500, loss=71442.2518879403\n",
      "Current iteration = 1000, loss=70251.55712281472\n",
      "Current iteration = 1500, loss=69726.56271011839\n",
      "Evaluated for {'degree': 6, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.8114820546834697\n",
      "Current iteration = 0, loss=105034.30098246678\n",
      "Current iteration = 500, loss=71133.76235712411\n",
      "Current iteration = 1000, loss=69712.36358960673\n",
      "Current iteration = 1500, loss=69016.92436053866\n",
      "Evaluated for {'degree': 7, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8127840420566488\n",
      "Current iteration = 0, loss=105036.21809295563\n",
      "Current iteration = 500, loss=71521.51078947377\n",
      "Current iteration = 1000, loss=70255.11530637856\n",
      "Current iteration = 1500, loss=69725.46666388788\n",
      "Evaluated for {'degree': 7, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.8115680349816985\n",
      "Current iteration = 0, loss=105021.63535924516\n",
      "Current iteration = 500, loss=71237.77830881253\n",
      "Current iteration = 1000, loss=69719.39075198385\n",
      "Current iteration = 1500, loss=69012.01318465926\n",
      "Evaluated for {'degree': 8, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8124401208637335\n",
      "Current iteration = 0, loss=105023.58543496698\n",
      "Current iteration = 500, loss=71634.75756334062\n",
      "Current iteration = 1000, loss=70301.02658155264\n",
      "Current iteration = 1500, loss=69718.50158287317\n",
      "Evaluated for {'degree': 8, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.8116540152799273\n",
      "Current iteration = 0, loss=105188.42693830693\n",
      "Current iteration = 500, loss=71375.08108566071\n",
      "Current iteration = 1000, loss=69785.10785719453\n",
      "Current iteration = 1500, loss=68995.56305322029\n",
      "Evaluated for {'degree': 9, 'gamma': 1e-06, 'lambda': 0.1} : loss = 0.8126120814601911\n",
      "Current iteration = 0, loss=105190.40766163776\n",
      "Current iteration = 500, loss=71772.40049637956\n",
      "Current iteration = 1000, loss=70397.5310783906\n",
      "Current iteration = 1500, loss=69760.36195353208\n",
      "Evaluated for {'degree': 9, 'gamma': 1e-06, 'lambda': 100.0} : loss = 0.8112241137887832\n",
      "======== Best test loss for parameters {'degree': 9, 'gamma': 1e-06, 'lambda': 100.0} ========\n",
      "======== Best test loss score 0.8112241137887832 ========\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import hyper_parameter_optimisation\n",
    "degrees = np.arange(3,10)\n",
    "lambdas = np.logspace(-1, 2,2)\n",
    "gammas = [1e-6] #np.logspace(-6, -5, 3)\n",
    "params={'degree':degrees,'gamma':gammas,'lambda':lambdas,}\n",
    "#call to the grid search function\n",
    "best_param = hyper_parameter_optimisation(params,X,y)\n",
    "#least_squares_SGD(y, X,np.zeros((X.shape[1])), 100, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param={'degree': 7, 'gamma': 1e-06, 'lambda': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated for {'degree': 5, 'lambda': 0.0001} : loss = 0.7726693494782806\n",
      "Evaluated for {'degree': 5, 'lambda': 0.00012742749857031334} : loss = 0.7726693274082003\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0001623776739188721} : loss = 0.7726692980044576\n",
      "Evaluated for {'degree': 5, 'lambda': 0.00020691380811147902} : loss = 0.772669259493117\n",
      "Evaluated for {'degree': 5, 'lambda': 0.00026366508987303583} : loss = 0.7726692095868173\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0003359818286283781} : loss = 0.7726691453472049\n",
      "Evaluated for {'degree': 5, 'lambda': 0.00042813323987193956} : loss = 0.7726690630139066\n",
      "Evaluated for {'degree': 5, 'lambda': 0.000545559478116852} : loss = 0.7726689577899933\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0006951927961775605} : loss = 0.772668823574352\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0008858667904100823} : loss = 0.772668652627313\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0011288378916846883} : loss = 0.7726684351570111\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0014384498882876629} : loss = 0.7726681588109289\n",
      "Evaluated for {'degree': 5, 'lambda': 0.0018329807108324356} : loss = 0.7726678080592538\n",
      "Evaluated for {'degree': 5, 'lambda': 0.002335721469090121} : loss = 0.7726673634572092\n",
      "Evaluated for {'degree': 5, 'lambda': 0.002976351441631319} : loss = 0.7726668007822524\n",
      "Evaluated for {'degree': 5, 'lambda': 0.00379269019073225} : loss = 0.7726660900535611\n",
      "Evaluated for {'degree': 5, 'lambda': 0.004832930238571752} : loss = 0.7726651944662797\n",
      "Evaluated for {'degree': 5, 'lambda': 0.00615848211066026} : loss = 0.7726640693088026\n",
      "Evaluated for {'degree': 5, 'lambda': 0.007847599703514606} : loss = 0.7726626609905187\n",
      "Evaluated for {'degree': 5, 'lambda': 0.01} : loss = 0.7726609063830541\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0001} : loss = 0.7711116550478582\n",
      "Evaluated for {'degree': 6, 'lambda': 0.00012742749857031334} : loss = 0.7711088998247062\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0001623776739188721} : loss = 0.7711054026127313\n",
      "Evaluated for {'degree': 6, 'lambda': 0.00020691380811147902} : loss = 0.7711009623374515\n",
      "Evaluated for {'degree': 6, 'lambda': 0.00026366508987303583} : loss = 0.7710953254405646\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0003359818286283781} : loss = 0.7710881728017008\n",
      "Evaluated for {'degree': 6, 'lambda': 0.00042813323987193956} : loss = 0.7710791037916336\n",
      "Evaluated for {'degree': 6, 'lambda': 0.000545559478116852} : loss = 0.7710676171405274\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0006951927961775605} : loss = 0.7710530882027211\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0008858667904100823} : loss = 0.7710347424488944\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0011288378916846883} : loss = 0.7710116251159207\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0014384498882876629} : loss = 0.770982567401073\n",
      "Evaluated for {'degree': 6, 'lambda': 0.0018329807108324356} : loss = 0.7709461500308237\n",
      "Evaluated for {'degree': 6, 'lambda': 0.002335721469090121} : loss = 0.7709006659455426\n",
      "Evaluated for {'degree': 6, 'lambda': 0.002976351441631319} : loss = 0.7708440851318261\n",
      "Evaluated for {'degree': 6, 'lambda': 0.00379269019073225} : loss = 0.7707740270740859\n",
      "Evaluated for {'degree': 6, 'lambda': 0.004832930238571752} : loss = 0.7706877500330453\n",
      "Evaluated for {'degree': 6, 'lambda': 0.00615848211066026} : loss = 0.7705821726713076\n",
      "Evaluated for {'degree': 6, 'lambda': 0.007847599703514606} : loss = 0.7704539527830863\n",
      "Evaluated for {'degree': 6, 'lambda': 0.01} : loss = 0.7702996595076796\n",
      "======== Best test loss for parameters {'degree': 6, 'lambda': 0.01} ========\n",
      "======== Best test loss score 0.7702996595076796 ========\n"
     ]
    }
   ],
   "source": [
    "degrees = np.arange(5,7)\n",
    "lambdas = np.logspace(-4, -2, 20)\n",
    "params={'degree':degrees,'lambda':lambdas}\n",
    "#call to the grid search function\n",
    "best_param = grid_search_cv(params,X,y,k_fold=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gamma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-0628adb8b385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdegree\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'degree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lambda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gamma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mexpanser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialExpansion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwith_interractions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gamma'"
     ]
    }
   ],
   "source": [
    "from build_polynomial import PolynomialExpansion\n",
    "\n",
    "degree  = best_param['degree']\n",
    "lambda_ = best_param['lambda']\n",
    "gamma=best_param['gamma']\n",
    "\n",
    "expanser = PolynomialExpansion(degree,with_interractions=True)\n",
    "tX       = expanser.expand(X)\n",
    "weights,loss_tr  = reg_logistic_regression(y,tX,lambda_=lambda_,initial_w=np.zeros((tX.shape[1])),max_iters=100,gamma=gamma)\n",
    "#weights,loss_tr = ridge_regression(y,tX,lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Augustin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "heavy_tailed_indices=[0,1,2,3,8,9,10,13,16,19,29]\n",
    "logged=np.array(X,copy=True)\n",
    "for i in heavy_tailed_indices:\n",
    "    l=np.log(logged[:,i])\n",
    "    l[l==-np.inf]=0\n",
    "    l[np.isnan(l)]=0\n",
    "    logged[:,i]=l\n",
    "logged=np.column_stack((logged,(X[:,11]>0)*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### For ridge reg ###########\n",
    "best_param={'degree': 6, 'lambda': 0.01}\n",
    "degree  = best_param['degree']\n",
    "lambda_ = best_param['lambda']\n",
    "expanser = PolynomialExpansion(degree,with_interractions=True)\n",
    "tX       = expanser.expand(X)\n",
    "weights,loss_tr = ridge_regression(y,tX,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic acc: 0.2259157624226309\n"
     ]
    }
   ],
   "source": [
    "print('logistic acc:' ,logistic_accuracy(y,tX,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x,y,w, print_=False):\n",
    "    pred=predict_labels(w, x)\n",
    "    false_positive=np.sum(pred>y)\n",
    "    false_negative=np.sum(pred<y)\n",
    "    true_positive=np.sum((pred==y) * (y==np.ones(len(y))*1))\n",
    "    true_negative=np.sum((pred==y) * (y==np.ones(len(y))*-1))\n",
    "    confusion_matrix=[[true_positive,false_positive],[false_negative,true_negative]]\n",
    "    if print_:\n",
    "        print(\"==============================\")\n",
    "        print('precision=',true_positive/(true_positive+false_positive))\n",
    "        print('accuracy=',(true_positive+true_negative)/len(pred))\n",
    "        print('recall=',true_positive/(true_positive+false_negative))\n",
    "        print('f1=',true_positive/(true_positive+0.5*(false_negative+false_positive)))\n",
    "        print(\"confusion matrix:\")\n",
    "        print(confusion_matrix[0])\n",
    "        print(confusion_matrix[1])\n",
    "        print(\"==============================\")   \n",
    "    \n",
    "    return (true_positive+true_negative)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "precision= 0.7510443336477564\n",
      "accuracy= 0.8141479568881305\n",
      "recall= 0.6706091853063975\n",
      "f1= 0.7085513059286427\n",
      "confusion matrix:\n",
      "[55735, 18475]\n",
      "[27376, 145121]\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8141479568881305"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(tX,y,weights, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "precision= 0.7574250625051515\n",
      "accuracy= 0.8150315961849481\n",
      "recall= 0.6634019564197279\n",
      "f1= 0.7073025239729323\n",
      "confusion matrix:\n",
      "[55136, 17658]\n",
      "[27975, 145938]\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8150315961849481"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(tX,y,weights, print_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 30)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "y_sub, X_sub, ids_sub = load_csv_data(DATA_TEST_PATH)\n",
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply same transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_sub = interpolator.interpolate(X_sub)\n",
    "Xt_sub = expanser.expand(Xt_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predictor(X,w):\n",
    "    sigm=sigmoid(X@w)\n",
    "    pred = [ -1 if x<0.5 else 1 for x in sigm]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Augustin\\Desktop\\ML\\Projet1\\Git\\ML-CS-433\\implementations.py:103: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.37866879722932995"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred = predict_labels(weights, Xt_sub)\n",
    "y_pred=logistic_predictor( Xt_sub,weights)\n",
    "np.sum(y_pred)/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output for submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "create_csv_submission(ids_sub, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
